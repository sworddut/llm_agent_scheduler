# LLM Agent Scheduler - 异步智能体调度器

## 愿景

本项目旨在构建一个先进的、异步的 LLM（大型语言模型）智能体调度系统。我们的目标是超越现有框架（如 LangChain Agents, AutoGen, CrewAI），解决它们在任务并行化、依赖管理和可扩展性方面的局限。我们引入了**计划与执行 (Plan-and-Execute)** 的新范式，通过一个中央调度器来管理一个由任务组成的有向无环图 (DAG)，从而实现高效、灵活、可观察的智能体协作。

## 核心架构

我们的系统由四个核心组件构成：

1.  **任务 (`Task`)**: 系统中的基本工作单元。每个任务包含其类型、负载 (payload) 和依赖关系。
2.  **调度器 (`Scheduler`)**: 系统的“大脑”。它负责接收新任务、管理任务之间的依赖关系，并将准备就绪的任务分派给智能体执行。
3.  **智能体 (`Agent`)**: 负责执行任务。我们有两种类型的智能体：
    *   `PlannerAgent`: 接收高级目标，并将其分解为一系列具体的、可执行的子任务（即任务 DAG）。
    *   `Agent`: 执行具体的任务，如调用工具、检索信息或生成内容。
4.  **主服务 (`main.py`)**: 基于 FastAPI 的异步服务，提供与调度器交互的 API 端点，用于提交任务和查询状态。

## 与现有框架的对比

| 特性 | LLM Agent Scheduler (本项目) | LangChain Agents | AutoGen | CrewAI |
| :--- | :--- | :--- | :--- | :--- |
| **任务模型** | 显式的任务 DAG | ReAct / 单步工具调用 | 多智能体对话 | 串行任务序列 |
| **执行策略** | 中央异步调度器 | 链式顺序执行 | 对话驱动 | 顺序流程 |
| **并行性** | 原生支持，自动执行无依赖的任务 | 有限（需手动实现） | 有限（基于对话） | 不支持 |
| **依赖管理** | 显式、自动化的 DAG 解析 | 隐式，难以管理 | 隐式，通过对话上下文 | 线性依赖 |
| **可扩展性** | 高（易于添加新任务和智能体） | 中等 | 中等 | 低 |
| **可观察性** | 高（任务状态、依赖关系清晰） | 低（难以追踪中间步骤） | 中等 | 中等 |

## 学术与实验规划

我们的目标是将此项目作为一篇学术论文，提交给顶级的 AI 或系统会议（如 NeurIPS, ICML, OSDI）。为此，我们正在进行一系列对比实验，以量化我们系统相较于 CrewAI 和 AutoGen 的优势。我们将重点评估以下指标：

*   **执行时间**: 完成复杂任务所需的总时间。
*   **LLM API 调用次数**: 衡量成本和效率。
*   **代码复杂性**: 实现相同任务所需的代码行数和逻辑复杂度。
*   **鲁棒性**: 在出现意外错误时的恢复能力。

实验设置位于 `experiments/` 目录下，包含一个共享的 `arxiv_search` 工具，以确保所有框架在同等条件下进行比较。

## 开发者快速上手指南

1.  **环境设置**:
    *   克隆本仓库。
    *   安装所需的 Python 包: `pip install -r requirements.txt`
    *   创建一个 `.env` 文件，并填入你的 `OPENAI_API_KEY`: `OPENAI_API_KEY="your_key_here"`

2.  **运行系统**:
    *   启动主服务: `uvicorn src.main:app --reload`
    *   服务将在 `http://127.0.0.1:8000` 上运行。

3.  **提交一个任务**:
    *   使用 `example_client.py` 脚本向系统提交一个高级任务。
    *   `python example_client.py "请研究一下关于‘大语言模型在软件工程中的应用’这个主题，并给我一份总结报告。"`
    *   客户端将持续监控任务状态，直到最终结果生成。

4.  **运行对比实验**:
    *   进入 `experiments/` 目录。
    *   分别运行每个框架的实验脚本:
        *   `python run_crewai.py`
        *   `python run_autogen.py`
        *   `python run_our_system.py`
    *   实验结果将打印到控制台，并保存在 `experiments/results/` 目录下。

## 未来路线图

- [ ] **增强的错误处理**: 实现更智能的重试和回退机制。
- [ ] **动态工具注册**: 允许在运行时向系统动态添加新工具。
- [ ] **UI 可视化**: 开发一个前端界面，用于实时监控任务 DAG 的执行过程。
- [ ] **集成测试**: 编写更全面的测试用例，确保系统的稳定性和可靠性。
- [ ] **支持多种 LLM**: 集成除 OpenAI 之外的其他模型提供商。

## 贡献

我们欢迎任何形式的贡献！如果您有任何想法、建议或发现了 bug，请随时提交 Issue 或 Pull Request。
